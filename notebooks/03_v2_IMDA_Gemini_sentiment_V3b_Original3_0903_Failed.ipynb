{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "#Gemini code for sentiment labelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNV1e3ASJha"
      },
      "source": [
        "## Setup - Install the Python SDK\n",
        "\n",
        "The Python SDK for the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OEoeosRTv-5"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "# !pip install genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "print(genai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tx5gxcYjfU3",
        "outputId": "5d238687-b956-4afe-b125-8254a5933323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCFF5VSTbcAR"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS9l5igubpHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362b35cb-b2df-4947-a4a9-d21d6a66f0a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore') # mute warnings\n",
        "\n",
        "import json\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYFrFPjSGNq"
      },
      "source": [
        "### Setup GEMINI API key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>.\n",
        "\n",
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n",
        "* Pass the key to `genai.configure(api_key=...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "# GOOGLE_API_KEY='AIzaSyAs_ZC-4ql0-L1l8THQWPWsz4ZDwz0fuOo'\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTl5NjtrhA0J"
      },
      "source": [
        "#### API LIMIT\n",
        "Note: For detailed information about the available models, including their capabilities and rate limits, see [Gemini models](https://ai.google.dev/models/gemini). There are options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\n",
        "\n",
        "The `genai` package also supports the PaLM  family of models, but only the Gemini models support the generic, multimodal capabilities of the `generateContent` method."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_info = genai.get_model(\"models/gemini-1.5-flash\")\n",
        "# Returns the \"context window\" for the model,\n",
        "# which is the combined input and output token limits.\n",
        "print(f\"model.input_token_limit: {model_info.input_token_limit}\")\n",
        "print(f\"model.output_token_limit: {model_info.output_token_limit}\")\n",
        "# model.input_token_limit: 1048576\n",
        "# model.output_token_limit: 8192"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "b9KsF0MlpoYC",
        "outputId": "071c2f67-8c41-4a52-f813-186fa91639ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.input_token_limit: 1048576\n",
            "model.output_token_limit: 8192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEgVOYu0pAr4"
      },
      "source": [
        "### Basics :\n",
        "\n",
        "- Load model\n",
        "- Test with Count tokens\n",
        "- Check context window: max input and output token limit\n",
        "\n",
        "Large language models have a context window, and the context length is often measured in terms of the **number of tokens**.\n",
        "you can determine the number of tokens per any `genai.protos.Content` object. In the simplest case, you can pass a query string to the `GenerativeModel.count_tokens` method as follows:\n",
        "\n",
        "temp remove   \"dialog_type\": \"bnk\" as bank, \"ins\" as insurance, \"banking\", \"insurance\", or \"telecom\", \"hotel\", \"holiday\", \"restaurant\", \"moe (singapre minister of education)\", \"msf (singapore Ministry of Finance)\", \"hdb (singapore Housing and Development Board)\" etc  // Type of service inquiry\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_system_prompt ='''\n",
        "You are an experienced Singaporean call center agent tasked with analyzing the sentiment of text from customer service calls. These calls are inbound inquiries related to banking, insurance, or telecom services, and the customers are speaking in Singlish, using various slang terms.\n",
        "Your goal is to rate the sentiment of each text chunk on a scale from -1.00 (negative) to 1.00 (positive) with 2 decimal precision. Additionally, provide a short explanation for each rating, explaining how the score is determined and why it is reasonable.\n",
        "Key Singlish Slang and Their Meanings:\n",
        "Shiok: good\n",
        "Sian: boring\n",
        "Jialat: troublesome\n",
        "Siao: crazy\n",
        "Paiseh: sorry\n",
        "Kao Pei: scold\n",
        "Bojio: never invite\n",
        "Suay: unfortunate\n",
        "Pokkai: bankrupt\n",
        "Atas: high-class\n",
        "Kena: suffered\n",
        "Kan Cheong: anxious\n",
        "\n",
        "Sentiment Rating Scale with Examples\n",
        "-1.00 (negative):\n",
        "\"Bad experiences that I have so I just want to clarify everything before I leave.\"\n",
        "\"Yes, that is very bad, so that's the reason why I want to change provider.\"\n",
        "\n",
        "-0.70 (negative):\n",
        "\"Recently I've been experiencing some slow Wi-Fi connection, so I would like to ask what is the problem.\"\n",
        "\"But then it was too late, so the flight left.\"\n",
        "\"or something cause I can t really travel and all of those are getting wasted now\"\n",
        "\n",
        "-0.50 (mild negative):\n",
        "\"We won't be able to claim this.\"\n",
        "\"Due to all this incident, I actually missed my flight.\"\n",
        "\"by the airlines is it or like people stole it\"\n",
        "\"if you are (uh) hosp~ hospitalised you have to provide with the (ppb) (uh) the invoice from the hospital and (ppb) (uh) the doctor s (uh) memo to (uh) upon thirty days before\"\n",
        "\"like claiming travel insurance recently I went (ppb) for a trip and I lost my (ppb) baggage I think it was stolen so (ppb) (um) I want\"\n",
        "\"twelve ya if you ll do at twelve month there will be some penalty incur\"\n",
        "\"okay so let s say for those people who under group A they need to pay a higher premium for their personal accident insurance\"\n",
        "\"yes correct rebooking fee and it was because of the last minute flight so it was very expensive\"\n",
        "\n",
        "-0.30 (slight negative):\n",
        "\"Okay, but if I exit that time frame, do I still get any coverage?\"\n",
        "\"no (uh) (uh) carry on sorry\"\n",
        "\"ya late payment charges\"\n",
        "\"\"there was a rebooking fee too is it\"\"\n",
        "\"how much extra would that cost and and if its like does it apply to any countries\"\n",
        "\"(uh) engaging in any high risk activities too\"\n",
        "\"[orh] so just now the hundred eighty two hundred twenty that [one] is (ppb) for high risk or for low risk\"\n",
        "\"so it takes five to six working days so okay can but I will have to make the down payment before I can apply for the car loan right\"\n",
        "\n",
        "-0.15 (neutral):\n",
        "\"Nope, he doesn't have any line now, ya.\"\n",
        "\"In case I miss the payment date.\"\n",
        "\"ya sorry\"\n",
        "\n",
        "0.00 (neutral):\n",
        "\"Okay, it follows if I were to travel overseas, or does it only apply?\"\n",
        "\"Okay, so annual plan for just yourself or for three of you?\"\n",
        "\"yes the price will differ depending on the storage of the phone\"\n",
        "\n",
        "0.15 (neutral):\n",
        "\"Something like Huawei or Oppo would be fine.\"\n",
        "\"Yeah, I think it would be best if we buy for both.\"\n",
        "\"ya okay\"\n",
        "\"(mm) fine\"\n",
        "\"bye bye\"\n",
        "\"[ah] I see okay\"\n",
        "\"correct\"\n",
        "\"sure may I know I m talking to\"\n",
        "\n",
        "0.30 (slight positive):\n",
        "\"Hi, good morning.\"\n",
        "\"How can I help you?\"\n",
        "\"I see, I see. Okay.\"\n",
        "\"okay okay\"\n",
        "\"yes yes\"\n",
        "\"okay alright\"\n",
        "\"which is more of a bargain\"\n",
        "\"okay is there anything else I could help you\"\n",
        "\n",
        "0.50 (mild positive):\n",
        "\"Storage, I think 256GB is good enough already.\"\n",
        "\"I think the rewards card will suit you the best.\"\n",
        "\"okay sure can thank you bye\"\n",
        "\"and also you are able to enjoy cashback for your land transport for example S_M_R_T buses and taxis\"\n",
        "\n",
        "\n",
        "0.70 (positive):\n",
        "\"Oh, I see, that's great. Okay, thank you.\"\n",
        "\"Oh, it's good to hear that, yeah, because I want to be unique.\"\n",
        "\"yes very good condition\"\n",
        "\"okay I think I meet the criteria [lah] the eligibility\"\n",
        "\n",
        "1.00 (positive):\n",
        "\"Yes, sure, I will. Thank you very much.\"\n",
        "\"No, that's all. You've been wonderful, thank you.\"\n",
        "\"Thank you so much.\"\n",
        "\"This is really helpful.\"\n",
        "\n",
        "Input Format:\n",
        "Each input will be a JSON object representing a single text chunk. Each batch contains 200 such text chunks, and each 'id' must correspond exactly between input and output.\n",
        "\n",
        "{\n",
        "    \"id\": int,  // Unique identifier for each sentence (eg. from 1 to 200 in each batch)\n",
        "    \"speaker_type\": \"client\" or \"agent\",  // Identifies the speaker\n",
        "    \"cleaned_text_for_sentiment\": \"string\"  // The text chunk to be analyzed\n",
        "}\n",
        "\n",
        "Example:\n",
        "json\n",
        "{\n",
        "    \"id\": 26,\n",
        "    \"speaker_type\": \"client\",\n",
        "    \"cleaned_text_for_sentiment\": \"Wah, the internet speed today damn slow leh.\"\n",
        "}\n",
        "\n",
        "Output Format：\n",
        "For each input text chunk, provide a corresponding JSON object with the sentiment analysis result. Ensure that each output 'id' matches the input 'id' precisely.\n",
        "json\n",
        "{\n",
        "    \"id\": int,  // Same 'id' as in the input\n",
        "    \"GEMINI\": float,  // Sentiment score between -1.00 to 1.00 with 2 decimal places\n",
        "    \"explanation\": \"string\"  // Short explanation explaining how and why the score was determined，make sure it is reasonable. If the explanation exceeds 20 tokens, please truncate it to 26 tokens for output.\n",
        "}\n",
        "\n",
        "Output Example:\n",
        "json\n",
        "{\n",
        "    \"id\": 26,\n",
        "    \"GEMINI\": -0.70,\n",
        "    \"explanation\": \"Expresses frustration over slow internet speed.\"\n",
        "}\n",
        "Below is the input text for analysis:\n",
        "'''\n"
      ],
      "metadata": {
        "id": "S8MVYYpnTq6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_system_prompt ='''\n",
        "You are an experienced Singaporean call center agent tasked with analyzing the sentiment of text from customer service calls. These calls are inbound inquiries related to banking, insurance, or telecom services, and the customers are speaking in Singlish, using various slang terms.\n",
        "Your goal is to rate the sentiment of each text chunk on a scale from -1.00 (negative) to 1.00 (positive) with 2 decimal precision. Additionally, provide a short explanation for each rating, explaining how the score is determined and why it is reasonable.\n",
        "Key Singlish Slang and Their Meanings:\n",
        "Shiok: good\n",
        "Sian: boring\n",
        "Jialat: troublesome\n",
        "Siao: crazy\n",
        "Paiseh: sorry\n",
        "Kao Pei: scold\n",
        "Bojio: never invite\n",
        "Suay: unfortunate\n",
        "Pokkai: bankrupt\n",
        "Atas: high-class\n",
        "Kena: suffered\n",
        "Kan Cheong: anxious\n",
        "\n",
        "Sentiment Rating Scale with Examples\n",
        "-1.00 (negative):\n",
        "\"Bad experiences that I have so I just want to clarify everything before I leave.\"\n",
        "\"Yes, that is very bad, so that's the reason why I want to change provider.\"\n",
        "\"But then it was too late, so the flight left.\"\n",
        "\n",
        "-0.50 (mild negative):\n",
        "\"We won't be able to claim this.\"\n",
        "\"Due to all this incident, I actually missed my flight.\"\n",
        "\n",
        "\n",
        "-0.30 (slight negative):\n",
        "\"how much extra would that cost and and if its like does it apply to any countries\"\n",
        "\"(uh) engaging in any high risk activities too\"\n",
        "\"[orh] so just now the hundred eighty two hundred twenty that [one] is (ppb) for high risk or for low risk\"\n",
        "\n",
        "-0.15 (neutral):\n",
        "\"Nope, he doesn't have any line now, ya.\"\n",
        "\"In case I miss the payment date.\"\n",
        "\"ya sorry\"\n",
        "\n",
        "0.00 (neutral):\n",
        "\"Okay, it follows if I were to travel overseas, or does it only apply?\"\n",
        "\"Okay, so annual plan for just yourself or for three of you?\"\n",
        "\"yes the price will differ depending on the storage of the phone\"\n",
        "\n",
        "0.15 (neutral):\n",
        "\"Something like Huawei or Oppo would be fine.\"\n",
        "\"Yeah, I think it would be best if we buy for both.\"\n",
        "\n",
        "0.30 (slight positive):\n",
        "\"Hi, good morning.\"\n",
        "\"How can I help you?\"\n",
        "\"I see, I see. Okay.\"\n",
        "\n",
        "0.50 (mild positive):\n",
        "\"Storage, I think 256GB is good enough already.\"\n",
        "\"I think the rewards card will suit you the best.\"\n",
        "\n",
        "1.00 (positive):\n",
        "\"No, that's all. You've been wonderful, thank you very much.\"\n",
        "\"This is really helpful.\"\n",
        "\n",
        "Input Format:\n",
        "Each input will be a JSON object representing a single text chunk. Each batch contains 100 such text chunks, and each 'id' must correspond exactly between input and output.\n",
        "\n",
        "{\n",
        "    \"id\": int,  // Unique identifier for each sentence (eg. from 1 to 100 in each batch)\n",
        "    \"cleaned_text_for_sentiment\": \"string\"  // The text chunk to be analyzed\n",
        "}\n",
        "\n",
        "Example:\n",
        "json\n",
        "{\n",
        "    \"id\": 26,\n",
        "    \"cleaned_text_for_sentiment\": \"Wah, the internet speed today damn slow leh.\"\n",
        "}\n",
        "\n",
        "Output Format：\n",
        "For each input text chunk, provide a corresponding JSON object with the sentiment analysis result. Ensure that each output 'id' matches the input 'id' precisely.\n",
        "json\n",
        "{\n",
        "    \"id\": int,  // Same 'id' as in the input\n",
        "    \"GEMINI\": float,  // Sentiment score between -1.00 to 1.00 with 2 decimal places\n",
        "    \"explanation\": \"string\"  // Short explanation explaining how and why the score was determined，make sure it is reasonable. If the explanation exceeds 20 tokens, please truncate it to 26 tokens for output.\n",
        "}\n",
        "\n",
        "Output Example:\n",
        "json\n",
        "{\n",
        "    \"id\": 26,\n",
        "    \"GEMINI\": -0.70,\n",
        "    \"explanation\": \"Expresses frustration over slow internet speed.\"\n",
        "}\n",
        "Below is the input text for analysis:\n",
        "'''\n"
      ],
      "metadata": {
        "id": "LDBpfRyKOeMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLjBmPCLpElk"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "model.count_tokens(sentiment_system_prompt)\n",
        "# Increase the timeout to 120 seconds\n",
        "# model.count_tokens(sentiment_system_prompt, request_options={\"timeout\": 120})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipa-8leY6wsK"
      },
      "source": [
        "## Load data to Encode messages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_df = pd.read_csv('/content/drive/MyDrive/PLP/input/IMDA_original3_RAW_176K.csv')\n",
        "# remove unnamed column\n",
        "# data_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "# remove none session id\n",
        "data_df = data_df[~data_df['session_id'].isna()]\n",
        "# cast session_id into integer\n",
        "data_df['session_id'] = data_df['session_id'].astype(int)\n",
        "data_df['speaker_id'] = data_df['speaker_id'].astype(int)\n",
        "# replace \"'\" to avoid potention quotation mark in json encoding/decoding issue\n",
        "data_df['cleaned_text_for_sentiment'] = data_df['cleaned_text_for_sentiment'].str.replace(\"'\",\" \")\n",
        "data_df.head()"
      ],
      "metadata": {
        "id": "nxo-AxKITn9T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "b5fe01df-ded9-431b-98bd-c1c9a7f1a6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            file_name  session_id  speaker_id speaker_type  \\\n",
              "0  app_0302_3604_phnd_cc-hol.TextGrid         302        3604       client   \n",
              "1  app_0302_0018_phnd_cc-hol.TextGrid         302          18        agent   \n",
              "2  app_0302_3604_phnd_cc-hol.TextGrid         302        3604       client   \n",
              "3  app_0302_3604_phnd_cc-hol.TextGrid         302        3604       client   \n",
              "4  app_0302_0018_phnd_cc-hol.TextGrid         302          18        agent   \n",
              "\n",
              "  dialog_type     x_min     x_max  \\\n",
              "0         hol   0.00000   3.09350   \n",
              "1         hol   3.12927   8.50931   \n",
              "2         hol   8.22110  21.06413   \n",
              "3         hol  21.06413  30.21838   \n",
              "4         hol  30.81900  42.98125   \n",
              "\n",
              "                                                text  \\\n",
              "0                                 call three holiday   \n",
              "1  hi good afternoon this is lily from A B C trav...   \n",
              "2  hi (uh) lily (uh) I'm joyce here (ppb) (um) I'...   \n",
              "3  (um) I'm looking into (um) a package to either...   \n",
              "4  hi miss joy we do have a package to korea and ...   \n",
              "\n",
              "                          cleaned_text_for_sentiment  word_count  duration  \\\n",
              "0                                 call three holiday           3   3.09350   \n",
              "1  hi good afternoon this is lily from A B C trav...          17   5.38004   \n",
              "2  hi (uh) lily (uh) I m joyce here (ppb) (um) I ...          20  12.84303   \n",
              "3  (um) I m looking into (um) a package to either...          15   9.15425   \n",
              "4  hi miss joy we do have a package to korea and ...          24  12.16225   \n",
              "\n",
              "   qualified_for_sentiment  \n",
              "0                    False  \n",
              "1                     True  \n",
              "2                     True  \n",
              "3                     True  \n",
              "4                     True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6b0f135-448f-438e-b91c-efb439e9dd50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>session_id</th>\n",
              "      <th>speaker_id</th>\n",
              "      <th>speaker_type</th>\n",
              "      <th>dialog_type</th>\n",
              "      <th>x_min</th>\n",
              "      <th>x_max</th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text_for_sentiment</th>\n",
              "      <th>word_count</th>\n",
              "      <th>duration</th>\n",
              "      <th>qualified_for_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>app_0302_3604_phnd_cc-hol.TextGrid</td>\n",
              "      <td>302</td>\n",
              "      <td>3604</td>\n",
              "      <td>client</td>\n",
              "      <td>hol</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>3.09350</td>\n",
              "      <td>call three holiday</td>\n",
              "      <td>call three holiday</td>\n",
              "      <td>3</td>\n",
              "      <td>3.09350</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>app_0302_0018_phnd_cc-hol.TextGrid</td>\n",
              "      <td>302</td>\n",
              "      <td>18</td>\n",
              "      <td>agent</td>\n",
              "      <td>hol</td>\n",
              "      <td>3.12927</td>\n",
              "      <td>8.50931</td>\n",
              "      <td>hi good afternoon this is lily from A B C trav...</td>\n",
              "      <td>hi good afternoon this is lily from A B C trav...</td>\n",
              "      <td>17</td>\n",
              "      <td>5.38004</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>app_0302_3604_phnd_cc-hol.TextGrid</td>\n",
              "      <td>302</td>\n",
              "      <td>3604</td>\n",
              "      <td>client</td>\n",
              "      <td>hol</td>\n",
              "      <td>8.22110</td>\n",
              "      <td>21.06413</td>\n",
              "      <td>hi (uh) lily (uh) I'm joyce here (ppb) (um) I'...</td>\n",
              "      <td>hi (uh) lily (uh) I m joyce here (ppb) (um) I ...</td>\n",
              "      <td>20</td>\n",
              "      <td>12.84303</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>app_0302_3604_phnd_cc-hol.TextGrid</td>\n",
              "      <td>302</td>\n",
              "      <td>3604</td>\n",
              "      <td>client</td>\n",
              "      <td>hol</td>\n",
              "      <td>21.06413</td>\n",
              "      <td>30.21838</td>\n",
              "      <td>(um) I'm looking into (um) a package to either...</td>\n",
              "      <td>(um) I m looking into (um) a package to either...</td>\n",
              "      <td>15</td>\n",
              "      <td>9.15425</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>app_0302_0018_phnd_cc-hol.TextGrid</td>\n",
              "      <td>302</td>\n",
              "      <td>18</td>\n",
              "      <td>agent</td>\n",
              "      <td>hol</td>\n",
              "      <td>30.81900</td>\n",
              "      <td>42.98125</td>\n",
              "      <td>hi miss joy we do have a package to korea and ...</td>\n",
              "      <td>hi miss joy we do have a package to korea and ...</td>\n",
              "      <td>24</td>\n",
              "      <td>12.16225</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6b0f135-448f-438e-b91c-efb439e9dd50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6b0f135-448f-438e-b91c-efb439e9dd50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6b0f135-448f-438e-b91c-efb439e9dd50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c694d35-2f73-4220-95a5-4a7dd9780fa7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c694d35-2f73-4220-95a5-4a7dd9780fa7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c694d35-2f73-4220-95a5-4a7dd9780fa7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.dialog_type.unique()"
      ],
      "metadata": {
        "id": "HzS4ZIE2xQCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6178da5c-e781-4374-b34c-dc82884fc107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['hol', 'hot', 'res', 'bnk', 'ins', 'tel', 'hdb', 'moe', 'msf'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df[data_df['dialog_type']=='bnk']['cleaned_text_for_sentiment'].head(10).tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0qy38ZMJxdc",
        "outputId": "6c049290-2b07-4fb0-8c38-d9102792175f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['call one banking hello thank you so much for calling A B C bank this is amy on the line and how can I help you today',\n",
              " 'call one banking',\n",
              " 'hi (uh) I would like to ask what is the what is the point of having a credit card (ppl)',\n",
              " '(uh) may I get your name please',\n",
              " '(uh) alice tan',\n",
              " 'alice tan okay (uh) good (uh) good evening alice so (um) you re asking about details of getting a credit card is it',\n",
              " 'yes',\n",
              " 'okay (uh) credit card wise (uh) what is the point of getting it (uh) credit card basically how it ha~ how it works is that you are able to spend money using this credit card and at the end of the month you will get a bill (um) whereby you pay off your bill at the end of the month so different credit we ha~ basically at A B C bank we have mainly three types of credit cards',\n",
              " 'so of course these three types of credit cards (um) help (uh) do have different (uh) features so we have the cashback credit card air miles credit card and rewards credit card so these three credit cards (um) of course they have they also have different perks okay (uh) (uh) (um) to reward our customers for using our cards',\n",
              " 'okay so (uh) what is the benefit of getting a cashback credit card']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Call Request\n",
        "1. schema constraint\n",
        "2. loop to query\n",
        "3. export results"
      ],
      "metadata": {
        "id": "4-P11YMYU1T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_json_controlled_generation(self):\n",
        "        # [START json_controlled_generation]\n",
        "        import typing_extensions as typing\n",
        "\n",
        "        class Recipe(typing.TypedDict):\n",
        "            recipe_name: str\n",
        "            ingredients: list[str]\n",
        "\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
        "        result = model.generate_content(\n",
        "            \"List a few popular cookie recipes.\",\n",
        "            generation_config=genai.GenerationConfig(\n",
        "                response_mime_type=\"application/json\", response_schema=list[Recipe]\n",
        "            ),\n",
        "        )\n",
        "        print(result)\n",
        "        # [END json_controlled_generation]\n"
      ],
      "metadata": {
        "id": "PFCZcKT9keEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKithEbeRzDX"
      },
      "outputs": [],
      "source": [
        "# schema constraint\n",
        "import typing_extensions as typing\n",
        "\n",
        "class SentimentScore(typing.TypedDict):\n",
        "  id: int\n",
        "  GEMINI: float\n",
        "  explanation: str\n",
        "\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash',\n",
        "                              generation_config={\"response_mime_type\": \"application/json\",\n",
        "                                                 \"response_schema\": list[SentimentScore]})\n",
        "\n",
        "generation_config = genai.types.GenerationConfig(\n",
        "        candidate_count=1,temperature=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "\n",
        "\n",
        "CHUNK_SIZE = 100  # Reduce chunk size to avoid exceeding response length limit\n",
        "\n",
        "# Split the DataFrame into chunks of 50 rows each\n",
        "data_df = data_df[data_df['dialog_type']=='bnk']\n",
        "chunks = np.array_split(data_df, np.ceil(len(data_df) / CHUNK_SIZE))"
      ],
      "metadata": {
        "id": "K-mGL6MYN3Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dict = chunks[0][[\"cleaned_text_for_sentiment\"]].reset_index(names='id').to_dict('records')\n",
        "response = model.generate_content(\n",
        "          sentiment_system_prompt + str(input_dict),\n",
        "          generation_config=generation_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "5MWzLD5VOAEX",
        "outputId": "abc9cef5-249f-4cc2-9e5b-bef3a1d6147e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-859e1f83f2fa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cleaned_text_for_sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response = model.generate_content(\n\u001b[0m\u001b[1;32m      3\u001b[0m           \u001b[0msentiment_system_prompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           generation_config=generation_config)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             response = getattr(self._session, method)(\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    542\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_scores_dict = json.loads(response.text)\n",
        "print(\"[DEBUG] http response dict: \", sentiment_scores_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNgt7iIaOFVj",
        "outputId": "02679533-23f9-4244-8a10-e14c4c9e3834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] http response dict:  [{'id': 607}, {'id': 608}, {'id': 609}, {'id': 610}, {'id': 611}, {'id': 612}, {'id': 613}, {'id': 614}, {'id': 615}, {'id': 616}, {'id': 617}, {'id': 618}, {'id': 619}, {'id': 620}, {'id': 621}, {'id': 622}, {'id': 623}, {'id': 624}, {'id': 625}, {'id': 626}, {'id': 627}, {'id': 628}, {'id': 629}, {'id': 630}, {'id': 631}, {'id': 632}, {'id': 633}, {'id': 634}, {'id': 635}, {'id': 636}, {'id': 637}, {'id': 638}, {'id': 639}, {'id': 640}, {'id': 641}, {'id': 642}, {'id': 643}, {'id': 644}, {'id': 645}, {'id': 646}, {'id': 647}, {'id': 648}, {'id': 649}, {'id': 650}, {'id': 651}, {'id': 652}, {'id': 653}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "failed_records = []\n",
        "faild_input_dfs = []\n",
        "queried_result_dfs = []\n",
        "merged_result_df = pd.DataFrame()\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    if i > 20:  # for test\n",
        "        break\n",
        "\n",
        "    print(f\"Processing chunk {i+1}/{len(chunks)}\")\n",
        "\n",
        "    input_dict = chunk[[\"speaker_type\",\"cleaned_text_for_sentiment\"]].reset_index(names='id').to_dict('records')\n",
        "    try:\n",
        "        # get Gemini response\n",
        "        response = model.generate_content(\n",
        "          sentiment_system_prompt + str(input_dict),\n",
        "                                    generation_config=generation_config)\n",
        "    except Exception as e:\n",
        "      print(f\"Failed at chunk {i+1}: API Request error: {e}\")\n",
        "      faild_input_dfs.append(chunk)\n",
        "      failed_records.append({\"id\":i+1, \"desc\": f\"API Request error: {e}\"})\n",
        "      queried_result_dfs.append(pd.DataFrame())\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "        if response:\n",
        "            sentiment_scores_dict = json.loads(response.text)\n",
        "            print(\"[DEBUG] http response dict: \", sentiment_scores_dict)\n",
        "            queried_result = pd.DataFrame.from_records(sentiment_scores_dict)\n",
        "            queried_result_dfs.append(queried_result)\n",
        "        else:\n",
        "            print(f\"Failed at chunk {i+1}: Empty Result!\")\n",
        "            faild_input_dfs.append(chunk)\n",
        "            failed_records.append({\"id\":i+1, \"desc\": f\"Empty Result\"})\n",
        "            queried_result_dfs.append(pd.DataFrame())\n",
        "            continue\n",
        "    except Exception as e:\n",
        "      print(f\"Failed at chunk {i+1}: JSON decode and to dataframe!\")\n",
        "      faild_input_dfs.append(chunk)\n",
        "      failed_records.append({\"id\":i+1, \"desc\": f\"JSON decode and to dataframe: {e}\"})\n",
        "      queried_result_dfs.append(pd.DataFrame())\n",
        "      continue\n",
        "    print(\"queried result: \", queried_result)\n",
        "    # join result to input chunk\n",
        "    try:\n",
        "      temp = chunk.join(queried_result.set_index('id'))\n",
        "      # Check for missing GEMINI values\n",
        "      if temp['GEMINI'].isna().any():\n",
        "        # Version 1: still add the rest matched result into the dataframe\n",
        "        print(f\"ALERT: Missing GEMINI value(s) at chunk {i+1}\")\n",
        "        # # Version 2: Raise an exception and treat as fail\n",
        "        # raise ValueError(f\"ALERT: Missing GEMINI value(s) at chunk {i+1}\")\n",
        "      merged_result_df = pd.concat([merged_result_df, temp])\n",
        "    except Exception as e:\n",
        "      print(f\"Failed at chunk {i+1}: Could not join result: {e}\")\n",
        "      faild_input_dfs.append(chunk)\n",
        "      failed_records.append({\"id\":i+1, \"desc\": f\"Could not join result: {e}\"})\n",
        "      continue\n",
        "\n",
        "    time.sleep(1)\n",
        "print(merged_result_df.shape)\n",
        "print(failed_records)"
      ],
      "metadata": {
        "id": "vZ9Uae6UmZak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "# Set up logging to capture detailed information\n",
        "logging.basicConfig(filename='genai_debug.log', level=logging.INFO)\n",
        "\n",
        "# Rest of your imports...\n",
        "\n",
        "CHUNK_SIZE = 50  # Further reduce chunk size if necessary\n",
        "# # Split the DataFrame into chunks of 50 rows each\n",
        "chunks = np.array_split(data_df, np.ceil(len(data_df) / CHUNK_SIZE))\n",
        "failed_records = []\n",
        "faild_input_dfs = []\n",
        "queried_result_dfs = []\n",
        "merged_result_df = pd.DataFrame()\n",
        "\n",
        "# Your existing code...\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    if i < 0 or i > 200:\n",
        "        continue\n",
        "\n",
        "    logging.info(f\"Processing chunk {i+1}/{len(chunks)}\")\n",
        "\n",
        "    input_dict = chunk[[\"speaker_type\", \"dialog_type\", \"cleaned_text_for_sentiment\"]].reset_index(names='id').to_dict('records')\n",
        "\n",
        "    try:\n",
        "        # Get Gemini response\n",
        "        response = model.generate_content(\n",
        "            sentiment_system_prompt + str(input_dict),\n",
        "            generation_config=generation_config\n",
        "        )\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed at chunk {i+1}: API Request error: {e}\")\n",
        "        faild_input_dfs.append(chunk)\n",
        "        failed_records.append({\"id\": i+1, \"desc\": f\"API Request error: {e}\"})\n",
        "        queried_result_dfs.append(pd.DataFrame())\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        logging.info(f\"Response from chunk {i+1}: {response.text}\")\n",
        "\n",
        "        if response:\n",
        "            sentiment_scores_dict = json.loads(response.text)\n",
        "            queried_result = pd.DataFrame.from_records(sentiment_scores_dict)\n",
        "            queried_result_dfs.append(queried_result)\n",
        "        else:\n",
        "            logging.warning(f\"Failed at chunk {i+1}: Empty Result!\")\n",
        "            faild_input_dfs.append(chunk)\n",
        "            failed_records.append({\"id\": i+1, \"desc\": \"Empty Result\"})\n",
        "            queried_result_dfs.append(pd.DataFrame())\n",
        "            continue\n",
        "    except json.JSONDecodeError as e:\n",
        "        logging.error(f\"Failed at chunk {i+1}: JSON decode error: {e} - Response: {response.text}\")\n",
        "        faild_input_dfs.append(chunk)\n",
        "        failed_records.append({\"id\": i+1, \"desc\": f\"JSON decode error: {e}\"})\n",
        "        queried_result_dfs.append(pd.DataFrame())\n",
        "        continue\n",
        "\n",
        "    # Join result to input chunk\n",
        "    try:\n",
        "        temp = chunk.join(queried_result.set_index('id'), on='id')\n",
        "        if temp['GEMINI'].isna().any():\n",
        "            logging.warning(f\"ALERT: Missing GEMINI value(s) at chunk {i+1}\")\n",
        "        merged_result_df = pd.concat([merged_result_df, temp])\n",
        "    except KeyError as e:\n",
        "        logging.error(f\"Failed at chunk {i+1}: Could not join result, missing GEMINI: {e}\")\n",
        "        faild_input_dfs.append(chunk)\n",
        "        failed_records.append({\"id\": i+1, \"desc\": f\"Missing GEMINI: {e}\"})\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed at chunk {i+1}: Could not join result: {e}\")\n",
        "        faild_input_dfs.append(chunk)\n",
        "        failed_records.append({\"id\": i+1, \"desc\": f\"Could not join result: {e}\"})\n",
        "        continue\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "logging.info(f\"Completed processing with {len(failed_records)} failures.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuuvI6I1Kt-u",
        "outputId": "c2d8feb0-7347-4d60-b7ed-059048059fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Failed at chunk 1: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 2: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 3: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 4: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 5: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 6: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 7: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 8: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 9: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 10: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 11: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 12: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 13: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 14: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 15: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 16: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 17: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 18: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 19: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 20: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 21: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 22: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 23: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n",
            "ERROR:root:Failed at chunk 24: API Request error: HTTPConnectionPool(host='localhost', port=44959): Read timed out. (read timeout=600.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_result_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "JVTXZXSXnfHO",
        "outputId": "fbf2b55d-c903-4a81-9022-d1024c8394f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee834f16-ec57-4dfc-beb9-5e922aac5361\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee834f16-ec57-4dfc-beb9-5e922aac5361')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee834f16-ec57-4dfc-beb9-5e922aac5361 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee834f16-ec57-4dfc-beb9-5e922aac5361');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_f08820f6-fac3-4047-9733-61af709850e4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f08820f6-fac3-4047-9733-61af709850e4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_result_df",
              "summary": "{\n  \"name\": \"merged_result_df\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of records Null Value matched: \", merged_result_df[merged_result_df['GEMINI'].isna()].shape[0])\n",
        "merged_result_df[merged_result_df['GEMINI'].isna()]"
      ],
      "metadata": {
        "id": "aJEFInx9Hbjt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_result_df.to_excel(\"/content/drive/MyDrive/PLP/IMDA_Original/IMDA_original3_V3b_Gemini_0903_200_a.xlsx\",index=False)\n",
        "merged_result_df1 = merged_result_df[~merged_result_df['GEMINI'].isna()]\n",
        "merged_result_df1.to_excel(\"/content/drive/MyDrive/PLP/IMDA_Original/IMDA_original3_V3b_Gemini_0903_200_ra.xlsx\",index=False)\n",
        "merged_result_df1.shape"
      ],
      "metadata": {
        "id": "VY3Dkrh9oknt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of failure: \", len(faild_input_dfs))\n",
        "pd.DataFrame.from_records(failed_records).to_csv(\n",
        "    \"/content/drive/MyDrive/PLP/IMDA_Original/IMDA_original3_V3b_Gemini_0903_200_failed_reason.csv\",index=False)\n",
        "\n",
        "failed_input_concat_df = pd.DataFrame()\n",
        "for failed_input_df in faild_input_dfs:\n",
        "    failed_input_concat_df = pd.concat([failed_input_concat_df,failed_input_df])\n",
        "failed_input_concat_df.to_excel(\"/content/drive/MyDrive/PLP/IMDA_Original/IMDA_original3_V3b_Gemini_0903_200_failed_input.xlsx\",index=False)\n",
        "failed_input_concat_df.shape[0], failed_input_concat_df.shape[0]//100"
      ],
      "metadata": {
        "id": "H-OkDv8LDphB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qt6Yj2JRf-0"
      },
      "source": [
        "# END reference\n",
        "\n",
        "-   Prompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for [prompt writing](https://ai.google.dev/docs/prompt_best_practices).\n",
        "-   Gemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available [Gemini models](https://ai.google.dev/models/gemini).\n",
        "-   Gemini offers options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}