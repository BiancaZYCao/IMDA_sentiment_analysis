{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0c9bbd-d48c-4ae8-8be1-703a2063aed3",
   "metadata": {},
   "source": [
    "# IMDA Dataset processing\n",
    "Updated Pre-Processing Steps for IMDA Dataset TextGrid Dialog Scripts\n",
    "\n",
    "1.\tMaintain Original Time Coordinate Separation:  \n",
    "\t•\tObjective: For easy processing and feature engineering, and the dataset is large enough to filter out adequate instatnces \n",
    "\t•\tImplementation: keep the segmentation based on the original x_min and x_max time coordinates as provided in the TextGrid files.  \n",
    "2.\tFilter Out Short Text Segments:\n",
    "\t•\tObjective: Focus on meaningful text segments that are likely to carry sentiment.\n",
    "\t•\tImplementation: Filter out text segments that contain fewer than 10 words before performing sentiment analysis.\n",
    "\t•\tReasoning: Short text segments (e.g., “yes”, “no”, “okay”) may not provide enough context for accurate labeling.\n",
    "3.\tAdd a Qualification Label for Sentiment Analysis:\n",
    "\t•\tObjective: Identify which text segments are eligible for sentiment analysis based on word count.\n",
    "\t•\tImplementation: Add a new column, `qualified_label_sentiment`, to the DataFrame: Set to True if the segment contains at least 10 words.\n",
    "\n",
    "Example Implementation:\n",
    "\n",
    " • Input Data: Text segments from IMDA dataset TextGrid dialog scripts.  \n",
    " • Process:  \n",
    "\t1.\tParse and load the TextGrid files, maintaining original time coordinates (x_min, x_max).  \n",
    "\t2.\tFor each text segment, count the number of words.  \n",
    "\t3.\tFilter out segments with fewer than 10 words.  \n",
    "\t4.\tAdd a qualified_for_sentiment column to indicate whether each segment meets the criteria for sentiment analysis.  \n",
    " • Outcome: A refined dataset with preserved time coordinates and only the most relevant text segments flagged for sentiment analysis.  \n",
    "\n",
    "This process update ensures that the sentiment analysis is performed on meaningful segments while respecting the original structure of the dialog scripts, leading to more accurate and context-aware results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef3715e-5a46-4193-ade5-5ae438da0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup - install library\n",
    "# !pip install textgrid\n",
    "# !pip install praatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0400dc-e410-443e-96d8-7463aefed79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from praatio import textgrid\n",
    "from utils_v2 import process_textgrid_file_to_sentences_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586fde15-e17a-4905-9438-13e70d235a62",
   "metadata": {},
   "source": [
    "## Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c75365-e516-4199-bc23-398ff2375968",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data processing output \n",
    "The combined call center dialogue data has been processed and displayed in a tabular format. Here is a brief overview of the data:\n",
    "\n",
    " • unique_id: The unique identifier for the session, derived from the filename. e.g. 0683  \n",
    " • speaker_id: The identifier for the speaker (e.g. 0013, 4366).  \n",
    " • speaker_type: The type of speaker (agent or client).  \n",
    " • dialog_type: The type of conversation topic.  \n",
    " • x_min: The start time of the spoken segment.  \n",
    " • x_max: The end time of the spoken segment.  \n",
    " • text: The transcribed text of the spoken segment.  \n",
    " • cleaned_text_sentiment: processed text of the spoken segment.  \n",
    " • qualified_label_sentiment:\n",
    " \n",
    "\n",
    "The data is sorted by the start time (x_min) to maintain the chronological order of the conversation.\n",
    "\n",
    "### Data understanding (GPT Gen)\n",
    "In TextGrid files, especially in the context of dialogue transcription,   \n",
    "special symbols like \\<B\\>, \\<Z\\>, and \\<S\\> often represent specific events or markers within the conversation. \n",
    "Here are some common interpretations:\n",
    "\n",
    "\t•\t<B>: This might indicate a backchannel, which are listener responses (like “uh-huh”, “right”, etc.) to show that they are following along but not taking the floor.\n",
    "\t•\t<Z>: This could represent a pause or silence in the conversation, possibly of significant duration.\n",
    "\t•\t<S>: This is often used to denote a short pause or a speaker’s hesitation, such as when they are thinking or momentarily pausing in their speech.\n",
    "\n",
    "These markers help in analyzing the structure and flow of conversations, providing insight into pauses, interruptions, and listener engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1fdec8-373a-4dde-969a-f9a0490ed4fc",
   "metadata": {},
   "source": [
    "## processing Session Call Center Design 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e30c66-4e86-4c5b-b978-3ae648c9adfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'app_1360_0018_phnd_cc-moe.TextGrid',\n",
       " 'session_id': '1360',\n",
       " 'speaker_id': '0018',\n",
       " 'speaker_type': 'agent',\n",
       " 'dialog_type': 'moe'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_filename_new(file_path):\n",
    "    \"\"\"\n",
    "    decode master data info from file name \n",
    "    like session index, speaker index, dialog type, etc.\n",
    "    \"\"\"\n",
    "    session_id = file_path.split('/')[-1][4:8]\n",
    "    speaker_id = file_path.split('/')[-1][9:13]\n",
    "    speaker_type = 'agent' if speaker_id.startswith('00') else 'client'\n",
    "    file_name = file_path.split('/')[-1]\n",
    "\n",
    "    dialog_type = os.path.splitext(file_name)[0][-3:]\n",
    "    \n",
    "    return {\n",
    "        'file_name': file_name,\n",
    "        'session_id': session_id,\n",
    "        'speaker_id': speaker_id,\n",
    "        'speaker_type': speaker_type,\n",
    "        'dialog_type': dialog_type,\n",
    "        }\n",
    "decode_filename_new(\"../data/input/TextGrid_Scripts_Session3/app_1360_0018_phnd_cc-moe.TextGrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee438280-0c0f-4ee5-92df-2c87814224eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_all_textgrid_files_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    wrapper function for iteration processing\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".TextGrid\"):\n",
    "            try:\n",
    "                file_path = os.path.join(directory_path, filename)\n",
    "                file_master_data = decode_filename_new(file_path)\n",
    "                temp_file_sentences = process_textgrid_file_to_sentences_v2(file_path, file_master_data)\n",
    "            except Exception as e:\n",
    "                print(\"error occurred at file \", file_path)\n",
    "                pass            \n",
    "            all_data += temp_file_sentences\n",
    "                \n",
    "    # Combine all dataframes into one\n",
    "    if all_data:\n",
    "        combined_df = pd.DataFrame(all_data).sort_values(by=['session_id', 'dialog_type', 'x_min']).reset_index(drop=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a5670c-bf74-47fc-b889-841a11fe6dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occurred at file  ../data/input/TextGrid_Scripts_Session1/app_0459_0021_phnd_cc-hot.TextGrid\n",
      "error occurred at file  ../data/input/TextGrid_Scripts_Session1/app_0246_0013_phnd_cc-res.TextGrid\n",
      "error occurred at file  ../data/input/TextGrid_Scripts_Session1/app_0188_0001_phnd_cc-hot.TextGrid\n",
      "error occurred at file  ../data/input/TextGrid_Scripts_Session3/app_0303_3606_phnd_cc-res.TextGrid\n",
      "error occurred at file  ../data/input/TextGrid_Scripts_Session3/app_1978_6956_phnd_cc-hdb.TextGrid\n"
     ]
    }
   ],
   "source": [
    "directory_path_1 = \"../data/input/TextGrid_Scripts_Session1/\"\n",
    "directory_path_3 = \"../data/input/TextGrid_Scripts_Session3/\"\n",
    "res_df_1 = process_all_textgrid_files_in_directory(directory_path_1)\n",
    "res_df_3 = process_all_textgrid_files_in_directory(directory_path_3)\n",
    "res_df_1.to_csv('../data/processed/sentence_level_script_data_raw_session1.csv',index=False)\n",
    "res_df_3.to_csv('../data/processed/sentence_level_script_data_raw_session3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b8d31be-a8f7-4438-9890-df1d8766b8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((259776, 8), (176292, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_1.shape, res_df_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de2485-6e61-449e-9e1c-8692d9d8b909",
   "metadata": {},
   "source": [
    "## Filtering eligible sentences for sentiment labelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f1121f2-c359-45f6-a950-3ccb172b1c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>session_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>dialog_type</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_0001_0010_phnd_cc-hol.TextGrid</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>agent</td>\n",
       "      <td>hol</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.06000</td>\n",
       "      <td>okay &lt;mandarin&gt;来来:lai lai&lt;/mandarin&gt; okay &lt;man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_0001_3002_phnd_cc-hol.TextGrid</td>\n",
       "      <td>1</td>\n",
       "      <td>3002</td>\n",
       "      <td>client</td>\n",
       "      <td>hol</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>up okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_0001_3002_phnd_cc-hol.TextGrid</td>\n",
       "      <td>1</td>\n",
       "      <td>3002</td>\n",
       "      <td>client</td>\n",
       "      <td>hol</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>7.97812</td>\n",
       "      <td>so (ppo) okay so hello I'm calling to (err)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_0001_3002_phnd_cc-hol.TextGrid</td>\n",
       "      <td>1</td>\n",
       "      <td>3002</td>\n",
       "      <td>client</td>\n",
       "      <td>hol</td>\n",
       "      <td>7.97812</td>\n",
       "      <td>10.43370</td>\n",
       "      <td>make some enquiry about (uh) travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_0001_3002_phnd_cc-hol.TextGrid</td>\n",
       "      <td>1</td>\n",
       "      <td>3002</td>\n",
       "      <td>client</td>\n",
       "      <td>hol</td>\n",
       "      <td>10.43370</td>\n",
       "      <td>12.49000</td>\n",
       "      <td>trip to (uh) korea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            file_name  session_id  speaker_id speaker_type  \\\n",
       "0  app_0001_0010_phnd_cc-hol.TextGrid           1          10        agent   \n",
       "1  app_0001_3002_phnd_cc-hol.TextGrid           1        3002       client   \n",
       "2  app_0001_3002_phnd_cc-hol.TextGrid           1        3002       client   \n",
       "3  app_0001_3002_phnd_cc-hol.TextGrid           1        3002       client   \n",
       "4  app_0001_3002_phnd_cc-hol.TextGrid           1        3002       client   \n",
       "\n",
       "  dialog_type     x_min     x_max  \\\n",
       "0         hol   0.00000   7.06000   \n",
       "1         hol   0.00000   3.13000   \n",
       "2         hol   3.13000   7.97812   \n",
       "3         hol   7.97812  10.43370   \n",
       "4         hol  10.43370  12.49000   \n",
       "\n",
       "                                                text  \n",
       "0  okay <mandarin>来来:lai lai</mandarin> okay <man...  \n",
       "1                                            up okay  \n",
       "2        so (ppo) okay so hello I'm calling to (err)  \n",
       "3                make some enquiry about (uh) travel  \n",
       "4                                 trip to (uh) korea  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove none session id\n",
    "data_raw_df = res_df_1\n",
    "data_raw_df = data_raw_df[~data_raw_df['session_id'].isna()]\n",
    "# cast session_id into integer\n",
    "data_raw_df['session_id'] = data_raw_df['session_id'].astype(int)\n",
    "data_raw_df['speaker_id'] = data_raw_df['speaker_id'].astype(int)\n",
    "data_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df73834f-dce4-4615-b86e-ad340213fc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text: 'This is an example'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text_for_word_count(text):\n",
    "    # Remove any string in brackets like (<xxx>) or [<xxx>] or <<xxx>>\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)  # Removes content within parentheses\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Removes content within square brackets\n",
    "    text = re.sub(r'\\<.*?\\>', '', text)  # Removes content within angle brackets\n",
    "\n",
    "    # Remove any character that is not an English alphabet or space\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Example usage\n",
    "example_text = \"This is an example (with noise) [and more noise] <<additional noise>> 123!\"\n",
    "cleaned_text = clean_text_for_word_count(example_text)\n",
    "print(f\"Cleaned Text: '{cleaned_text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18751b7e-f6e1-49f8-bc4e-5533868ebcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_w_stats_df number of records:  259776\n",
      "number of qualified records:  136831\n"
     ]
    }
   ],
   "source": [
    "def clean_text_for_sentiment(text):\n",
    "    # Remove specific markers <B>, <S>, <Z>\n",
    "    text = re.sub(r'<B>|<S>|<Z>', '', text)\n",
    "    # Remove extra whitespace\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def count_unique_words(text):\n",
    "    # Split the text into words and count unique words\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words)\n",
    "\n",
    "def add_qualification_label(df):\n",
    "    # Clean the text and count words\n",
    "    df['cleaned_text_for_sentiment'] = df['text'].apply(clean_text_for_sentiment)\n",
    "    df['word_count'] = df['text'].apply(clean_text_for_word_count).apply(count_unique_words)\n",
    "    df = df.assign(duration=lambda x: x.x_max - x.x_min)\n",
    "    # Filter rows where the word count is less than 10 and duration less than 15 seconds\n",
    "    # filtered_df = df[df['word_count'] >= 6][df['duration'] <= 15].reset_index(drop=True)\n",
    "    # Add a qualification label: True if the segment contains at least 10 words and duration less than 15 seconds\n",
    "    df['qualified_for_sentiment'] = (df['word_count'] >= 7) & (df['duration'] <= 15)\n",
    "    return df\n",
    "\n",
    "def filter_by_qualified(df):\n",
    "    filtered_df = df[df['qualified_for_sentiment'] == True].reset_index(drop=True)\n",
    "    # filtered_df = filtered_df.drop(columns=['text','word_count','duration'])\n",
    "    return filtered_df\n",
    "\n",
    "data_w_stats_df = add_qualification_label(data_raw_df)\n",
    "data_w_stats_df.to_csv('../data/processed/sentence_level_script_data_raw_session1.csv',index=False)\n",
    "print(\"data_w_stats_df number of records: \", data_w_stats_df.shape[0])\n",
    "qualified_data_df = filter_by_qualified(data_w_stats_df)\n",
    "qualified_data_df.to_csv('../data/processed/sentence_level_script_data_filtered_session1.csv',index=False)\n",
    "print(\"number of qualified records: \", qualified_data_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f387f72-8804-42a4-a80f-9988461bd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qualified_data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f049b-cc0e-49b4-b193-2008457166d8",
   "metadata": {},
   "source": [
    "## Call center design 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0618ac96-9b38-4e76-b035-836ceac0353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_w_stats_df number of records:  176292\n",
      "number of qualified records:  77807\n"
     ]
    }
   ],
   "source": [
    "# remove none session id\n",
    "data_raw_df = res_df_3\n",
    "data_raw_df = data_raw_df[~data_raw_df['session_id'].isna()]\n",
    "# cast session_id into integer\n",
    "data_raw_df['session_id'] = data_raw_df['session_id'].astype(int)\n",
    "data_raw_df['speaker_id'] = data_raw_df['speaker_id'].astype(int)\n",
    "data_raw_df.head()\n",
    "\n",
    "data_w_stats_df = add_qualification_label(data_raw_df)\n",
    "data_w_stats_df.to_csv('../data/processed/sentence_level_script_data_raw_session3.csv',index=False)\n",
    "print(\"data_w_stats_df number of records: \", data_w_stats_df.shape[0])\n",
    "qualified_data_df = filter_by_qualified(data_w_stats_df)\n",
    "qualified_data_df.to_csv('../data/processed/sentence_level_script_data_filtered_session3.csv',index=False)\n",
    "print(\"number of qualified records: \", qualified_data_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071df4a-c5c0-4ffb-91f0-9ac48fa1f09b",
   "metadata": {},
   "source": [
    "# The END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
